{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920728d4-6f6c-4643-96ed-5c76ad2c1f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.60.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.61.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery[pandas] in /opt/conda/lib/python3.10/site-packages (3.25.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.32.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.5)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.5)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (2.9.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (2.0.3)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (14.0.2)\n",
      "Requirement already satisfied: db-dtypes<2.0.0dev,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from db-dtypes<2.0.0dev,>=0.3.0->google-cloud-bigquery[pandas]) (1.25.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.0->google-cloud-bigquery[pandas]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.0->google-cloud-bigquery[pandas]) (2024.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery[pandas]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Downloading google_cloud_aiplatform-1.61.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-resumable-media, google-api-core, google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-resumable-media\n",
      "    Found existing installation: google-resumable-media 2.7.1\n",
      "    Uninstalling google-resumable-media-2.7.1:\n",
      "      Successfully uninstalled google-resumable-media-2.7.1\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.60.0\n",
      "    Uninstalling google-cloud-aiplatform-1.60.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.60.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.19.1 google-cloud-aiplatform-1.61.0 google-cloud-storage-2.18.2 google-resumable-media-2.7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                        google-cloud-storage \\\n",
    "                        'google-cloud-bigquery[pandas]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c0798f-634c-4cbf-aea6-7bab0b8db0ae",
   "metadata": {},
   "source": [
    "Restart kernel after installs so that your environment can access the new packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d66858c-bfc8-4f73-b8ad-5225d7fb4da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d2cf9-07e2-4c23-a27d-39a41c821d16",
   "metadata": {},
   "source": [
    "Setup the environment values for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf01f35-9f5b-4052-ba35-c2f298c5c9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-east1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c9fae-08a0-4649-a071-1d1af1c31a20",
   "metadata": {},
   "source": [
    "Import and initialize the Vertex AI Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d924de9-b280-4a95-937c-15e7ea5d5810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "vertexai.init(project = PROJECT_ID,\n",
    "              location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f649dd8-30a4-4b23-8eda-deaca7455896",
   "metadata": {},
   "source": [
    "The dataset used for this lab is the StackOverflow dataset. This public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset.\n",
    "\n",
    "Stack Overflow is the largest online community for programmers to learn, share their knowledge, and advance their careers. Updated on a quarterly basis, this BigQuery dataset includes an archive of Stack Overflow content, including posts, votes, tags, and badges. This dataset is updated to mirror the Stack Overflow content on the Internet Archive, and is also available through the Stack Exchange Data Explorer.\n",
    "\n",
    "The BigQuery table is too large to fit into memory, so you need to write a generator called query_bigquery_chunks to yield chunks of the dataframe for processing. Additionally, an extra column title_with_body is added, which is a concatenation of the question title and body that will be used for creating embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f4e5a-bd0e-4b7d-9e47-d5da8a91885f",
   "metadata": {},
   "source": [
    "Import the libraries and initialize the BigQuery client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe08813e-adf2-4a90-80e7-fcec2b22a7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Any, Generator\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01b688-dffc-4497-a584-93da7bfcccc8",
   "metadata": {},
   "source": [
    "Define the BigQuery query for the remote dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be24ecc0-7006-484b-868f-461f222355ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT distinct q.id, q.title, q.body\n",
    "        FROM (SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` where Score>0 ORDER BY View_Count desc) AS q\n",
    "        LIMIT {limit} OFFSET {offset};\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9338672-6fdb-4d24-b8a0-3dd5fd319935",
   "metadata": {},
   "source": [
    "Create a function to access the BigQuery data in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b3517f-4dd7-4ab1-ab5b-df8e906481db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_bigquery_chunks(\n",
    "    max_rows: int, rows_per_chunk: int, start_chunk: int = 0\n",
    ") -> Generator[pd.DataFrame, Any, None]:\n",
    "    for offset in range(start_chunk, max_rows, rows_per_chunk):\n",
    "        query = QUERY_TEMPLATE.format(limit=rows_per_chunk, offset=offset)\n",
    "        query_job = client.query(query)\n",
    "        rows = query_job.result()\n",
    "        df = rows.to_dataframe()\n",
    "        df[\"title_with_body\"] = df.title + \"\\n\" + df.body\n",
    "        yield df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eec4c5-6bf3-4239-b8da-411e6a69bac4",
   "metadata": {},
   "source": [
    "Get a dataframe of 1000 rows for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3100d740-f1b9-4713-8985-8b764c49f226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723298849.983210     405 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>title_with_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17836143</td>\n",
       "      <td>I use string.split(\"|\") and I am getting array...</td>\n",
       "      <td>&lt;p&gt;My code:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;  result =\"sub||...</td>\n",
       "      <td>I use string.split(\"|\") and I am getting array...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17819298</td>\n",
       "      <td>Jade HTML attribute called \"attribute\"</td>\n",
       "      <td>&lt;p&gt;Working with Polymer Project markup, the &lt;c...</td>\n",
       "      <td>Jade HTML attribute called \"attribute\"\\n&lt;p&gt;Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18075375</td>\n",
       "      <td>Create custom ListView with shadow</td>\n",
       "      <td>&lt;p&gt;How could I create custom &lt;code&gt;ListView&lt;/c...</td>\n",
       "      <td>Create custom ListView with shadow\\n&lt;p&gt;How cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18179726</td>\n",
       "      <td>how to open pdf file to another tab in browser...</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;im making currently making my thesi...</td>\n",
       "      <td>how to open pdf file to another tab in browser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18173191</td>\n",
       "      <td>UICollectionReusableView method not being called</td>\n",
       "      <td>&lt;p&gt;I want my sections in the &lt;code&gt;UICollectio...</td>\n",
       "      <td>UICollectionReusableView method not being call...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  17836143  I use string.split(\"|\") and I am getting array...   \n",
       "1  17819298             Jade HTML attribute called \"attribute\"   \n",
       "2  18075375                 Create custom ListView with shadow   \n",
       "3  18179726  how to open pdf file to another tab in browser...   \n",
       "4  18173191   UICollectionReusableView method not being called   \n",
       "\n",
       "                                                body  \\\n",
       "0  <p>My code:</p>\\n\\n<pre><code>  result =\"sub||...   \n",
       "1  <p>Working with Polymer Project markup, the <c...   \n",
       "2  <p>How could I create custom <code>ListView</c...   \n",
       "3  <pre><code>im making currently making my thesi...   \n",
       "4  <p>I want my sections in the <code>UICollectio...   \n",
       "\n",
       "                                     title_with_body  \n",
       "0  I use string.split(\"|\") and I am getting array...  \n",
       "1  Jade HTML attribute called \"attribute\"\\n<p>Wor...  \n",
       "2  Create custom ListView with shadow\\n<p>How cou...  \n",
       "3  how to open pdf file to another tab in browser...  \n",
       "4  UICollectionReusableView method not being call...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = next(query_bigquery_chunks(max_rows=1000, rows_per_chunk=1000))\n",
    "\n",
    "# Examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3834cd43-88ea-427d-b293-79303d3b1f25",
   "metadata": {},
   "source": [
    "Load the Vertex AI Embeddings for Text model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056b2fbc-23af-4cda-95ff-0d2b974cf16e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88addcd-8879-49d7-9ec4-6da00aa35e09",
   "metadata": {},
   "source": [
    "Define an embedding method that uses the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87693dc-bd4a-404e-9071-1bf3469129ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_texts_to_embeddings(sentences: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        embeddings = model.get_embeddings(sentences)\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(sentences))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799dcc0-0822-48f9-859d-48b57dda3779",
   "metadata": {},
   "source": [
    "According to the documentation, each request can handle up to 5 text instances. So we will need to split the BigQuery question results in batches of 5 before sending to the embedding API.\n",
    "\n",
    "Create a generate_batches to split results in batches of 5 to be sent to the embeddings API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de37b89f-3006-4984-ba6d-381fa2c003fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Generator, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Generator function to yield batches of sentences\n",
    "def generate_batches(\n",
    "    sentences: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        yield sentences[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182eaed-3c93-4bc8-82d1-b64b851bb276",
   "metadata": {},
   "source": [
    "Encapsulate the process of generating batches and calling the embeddings API in a method called encode_text_to_embedding_batched. This method also handles rate-limiting using time.sleep. For production use cases, you would want a more sophisticated rate-limiting mechanism that takes retries into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8326da29-b978-4d6e-a45e-5b9d481c7642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_text_to_embedding_batched(\n",
    "    sentences: List[str], api_calls_per_second: int = 10, batch_size: int = 5\n",
    ") -> Tuple[List[bool], np.ndarray]:\n",
    "\n",
    "    embeddings_list: List[List[float]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(sentences, batch_size)\n",
    "\n",
    "    seconds_per_job = 1 / api_calls_per_second\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(\n",
    "            batches, total=math.ceil(len(sentences) / batch_size), position=0\n",
    "        ):\n",
    "            futures.append(\n",
    "                executor.submit(functools.partial(encode_texts_to_embeddings), batch)\n",
    "            )\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "\n",
    "    is_successful = [\n",
    "        embedding is not None for sentence, embedding in zip(sentences, embeddings_list)\n",
    "    ]\n",
    "    embeddings_list_successful = np.squeeze(\n",
    "        np.stack([embedding for embedding in embeddings_list if embedding is not None])\n",
    "    )\n",
    "    return is_successful, embeddings_list_successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e2049-3467-4648-8c7e-0840fe067fc2",
   "metadata": {},
   "source": [
    "Test the encoding function by encoding a subset of data and see if the embeddings and distance metrics make sense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "002af45f-8c88-4f12-86ae-8065182b6667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb43fdaa5b1e4cd09be012b1ab03356c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode a subset of questions for validation\n",
    "questions = df.title.tolist()[:500]\n",
    "is_successful, question_embeddings = encode_text_to_embedding_batched(\n",
    "    sentences=df.title.tolist()[:500]\n",
    ")\n",
    "\n",
    "# Filter for successfully embedded sentences\n",
    "questions = np.array(questions)[is_successful]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd526b-5538-42fe-8c24-b7b4b2533ae2",
   "metadata": {},
   "source": [
    "Save the dimension size for later usage when creating the Vertex AI Vector Search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f63715-04fe-4650-acce-0e301e1996ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "DIMENSIONS = len(question_embeddings[0])\n",
    "\n",
    "print(DIMENSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b8101-a5ed-4541-9bda-554aec2c02cc",
   "metadata": {},
   "source": [
    "Sort questions in order of similarity. According to the embedding documentation, the similarity of embeddings is calculated using the dot-product, with np.dot. Once you have the similarity score, sort the results and print them for inspection. 1 means very similar, 0 means very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c38acbf-c179-4b22-af83-b4c9a74d2120",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query question = Having issues preserving variable contents in closure\n",
      "\t0: Having issues preserving variable contents in closure: 0.9999981469995682\n",
      "\t1: Return reference to argument object: 0.542115084178388\n",
      "\t2: Global vars with jsFiddle: 0.5274585932955009\n",
      "\t3: Session variable is lost on RedirectToAction in IE: 0.4960334294011826\n",
      "\t4: Uncaught TypeError: Object function (){return i.apply(this,arguments)} has no method 'on': 0.4859915756741863\n",
      "\t5: How do I reference the outer \"$(this)\" in jquery?: 0.48440742705501616\n",
      "\t6: Saving function evaluations while using std::min_element(): 0.4759444377204304\n",
      "\t7: Dictionary is empty on deserialization: 0.4735764952108908\n",
      "\t8: Why do I see duplicate javascript async responses?: 0.4700778842273614\n",
      "\t9: Java regex finds only last match when I want all: 0.46294989592238034\n",
      "\t10: flot chart plothover event fires but item is always null in bar chart: 0.45219314193317717\n",
      "\t11: I use string.split(\"|\") and I am getting array that have every char in one array element: 0.44981505855494064\n",
      "\t12: How would one go about implementing `zipWithIndex` in underscore.js?: 0.4463211593768855\n",
      "\t13: Using jQuery append with Grails remotefunction: 0.4435830635489859\n",
      "\t14: How to get the result value of Alamofire.request().responseJSON in swift 2?: 0.43374324527681485\n",
      "\t15: What's the difference between class variables of different types?: 0.43043566594993743\n",
      "\t16: calling static array from another class: 0.4219430854294215\n",
      "\t17: UICollectionReusableView method not being called: 0.4190261826434811\n",
      "\t18: jQuery .ajax post fails with large JSON object: 0.416622560760161\n",
      "\t19: Regex: remove non-alphanumeric chars, multiple whitespaces and trim() all together: 0.41178816230805915\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "question_index = random.randint(0, 99)\n",
    "\n",
    "print(f\"Query question = {questions[question_index]}\")\n",
    "\n",
    "# Get similarity scores for each embedding by using dot-product.\n",
    "scores = np.dot(question_embeddings[question_index], question_embeddings.T)\n",
    "\n",
    "# Print top 20 matches\n",
    "for index, (question, score) in enumerate(\n",
    "    sorted(zip(questions, scores), key=lambda x: x[1], reverse=True)[:20]\n",
    "):\n",
    "    print(f\"\\t{index}: {question}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387b6bd-b602-4d6d-875a-3aa9594dc7bb",
   "metadata": {},
   "source": [
    "Save the embeddings in JSONL format. The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4dbd52-166d-4fad-869d-b3d196827ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings directory: /tmp/tmp1fe4ylub\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "embeddings_file_path = Path(tempfile.mkdtemp())\n",
    "\n",
    "print(f\"Embeddings directory: {embeddings_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced4bae-f636-42e1-9d3a-35654d89fbfc",
   "metadata": {},
   "source": [
    "Write embeddings in batches to prevent out-of-memory errors. Notice we are only using 5000 questions so that the embedding creation process and indexing is faster. The dataset contains more than 50,000 questions. This step will take around 5 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d68014-6f99-4c81-b7e8-8ce119da572f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e58a67d1e04626b539e68efdab0a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunk of rows from BigQuery:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daba5594cbde4b82bc2b1ab8e4416e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cde2cc53994fc1af998466136a22a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5812cf394934f3fa39d7a90a5a1f0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9a233e01474ba399ce2fd33e1ed37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16aab0d0388c4bdb85a35cd09dc384ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "BQ_NUM_ROWS = 5000\n",
    "BQ_CHUNK_SIZE = 1000\n",
    "BQ_NUM_CHUNKS = math.ceil(BQ_NUM_ROWS / BQ_CHUNK_SIZE)\n",
    "\n",
    "START_CHUNK = 0\n",
    "\n",
    "# Create a rate limit of 300 requests per minute. Adjust this depending on your quota.\n",
    "API_CALLS_PER_SECOND = 300 / 60\n",
    "# According to the docs, each request can process 5 instances per request\n",
    "ITEMS_PER_REQUEST = 5\n",
    "\n",
    "# Loop through each generated dataframe, convert\n",
    "for i, df in tqdm(\n",
    "    enumerate(\n",
    "        query_bigquery_chunks(\n",
    "            max_rows=BQ_NUM_ROWS, rows_per_chunk=BQ_CHUNK_SIZE, start_chunk=START_CHUNK\n",
    "        )\n",
    "    ),\n",
    "    total=BQ_NUM_CHUNKS - START_CHUNK,\n",
    "    position=-1,\n",
    "    desc=\"Chunk of rows from BigQuery\",\n",
    "):\n",
    "    # Create a unique output file for each chunk\n",
    "    chunk_path = embeddings_file_path.joinpath(\n",
    "        f\"{embeddings_file_path.stem}_{i+START_CHUNK}.json\"\n",
    "    )\n",
    "    with open(chunk_path, \"a\") as f:\n",
    "        id_chunk = df.id\n",
    "\n",
    "        # Convert batch to embeddings\n",
    "        is_successful, question_chunk_embeddings = encode_text_to_embedding_batched(\n",
    "            sentences=df.title_with_body.to_list(),\n",
    "            api_calls_per_second=API_CALLS_PER_SECOND,\n",
    "            batch_size=ITEMS_PER_REQUEST,\n",
    "        )\n",
    "\n",
    "        # Append to file\n",
    "        embeddings_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"embedding\": [str(value) for value in embedding],\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            for id, embedding in zip(id_chunk[is_successful], question_chunk_embeddings)\n",
    "        ]\n",
    "        f.writelines(embeddings_formatted)\n",
    "\n",
    "        # Delete the DataFrame and any other large data structures\n",
    "        del df\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2898f-4c55-4601-9017-418fb7dc6ed8",
   "metadata": {},
   "source": [
    "Upload the text-embeddings to Cloud Storage, so that Vertex AI Vector Search can access them later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cedf66-508e-4c10-b0bb-d8e87eef2b0f",
   "metadata": {},
   "source": [
    "Define a bucket where you will store your embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18d18dd6-257f-49dc-823d-18f9c79c717b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://{PROJECT_ID}-unique\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b91c1c-25c1-4d62-9e41-17e9ac79350b",
   "metadata": {},
   "source": [
    "Create your Cloud Storage bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ede9f16-23e3-47bc-b5a2-ba853e94aaf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1723299513.278119     405 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-03-a735eb03bf93-unique/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c73616-2d9a-4c8a-9321-b811daf094a5",
   "metadata": {},
   "source": [
    "Upload the training data to a Google Cloud Storage bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17de5062-2db1-459c-ba4b-8dfd729a92aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1723299543.706102     405 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///tmp/tmp1fe4ylub/tmp1fe4ylub_2.json [Content-Type=application/json]...\n",
      "Copying file:///tmp/tmp1fe4ylub/tmp1fe4ylub_0.json [Content-Type=application/json]...\n",
      "Copying file:///tmp/tmp1fe4ylub/tmp1fe4ylub_1.json [Content-Type=application/json]...\n",
      "Copying file:///tmp/tmp1fe4ylub/tmp1fe4ylub_3.json [Content-Type=application/json]...\n",
      "Copying file:///tmp/tmp1fe4ylub/tmp1fe4ylub_4.json [Content-Type=application/json]...\n",
      "- [5/5 files][  6.2 MiB/  6.2 MiB] 100% Done                                    \n",
      "Operation completed over 5 objects/6.2 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "remote_folder = f\"{BUCKET_URI}/{embeddings_file_path.stem}/\"\n",
    "! gsutil -m cp -r {embeddings_file_path}/* {remote_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d275e878-2755-4058-80e2-1c7d02bea1c4",
   "metadata": {},
   "source": [
    "Setup your index name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "628f42dc-7584-4686-8b61-7fc10a870788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"stack_overflow\"\n",
    "DESCRIPTION = \"question titles and bodies from stackoverflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd873ac-5b13-4e30-a0fd-d5d3b0f18da6",
   "metadata": {},
   "source": [
    "Create the index. Notice that the index reads the embeddings from the Cloud Storage bucket. The indexing process can take from 45 minutes up to 60 minutes. Wait for completion, and then proceed. You can open a different Google Cloud Console page, navigate to Vertex AI Vector search, and see how the index is being created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc21e7-594b-485c-9cc0-e94492b081d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/965332343123/locations/us-east1/indexes/7312517584803332096/operations/8007708138159472640\n",
      "MatchingEngineIndex created. Resource name: projects/965332343123/locations/us-east1/indexes/7312517584803332096\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/965332343123/locations/us-east1/indexes/7312517584803332096')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\n",
    "\n",
    "DIMENSIONS = 768\n",
    "\n",
    "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    contents_delta_uri=remote_folder,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=150,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=80,\n",
    "    description=DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f7d65-0fcd-4da4-b7df-88f24daaebeb",
   "metadata": {},
   "source": [
    "Reference the index name to make sure it got created successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f94966c-9b9c-4db7-801b-3e762cce220b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/965332343123/locations/us-east1/indexes/7312517584803332096'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5dce90-9870-4fb6-a739-deaf63c44b47",
   "metadata": {},
   "source": [
    "Using the resource name, you can retrieve an existing MatchingEngineIndex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd437c97-7341-4f35-be39-31e03ee55051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328fc2a-0bba-4ec0-b6b0-32a1ff3de136",
   "metadata": {},
   "source": [
    "Create an IndexEndpoint so that it can be accessed via an API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f5f97a-1d17-4730-8975-76fc161c5512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/965332343123/locations/us-east1/indexEndpoints/3060310296007540736/operations/7460520783433957376\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/965332343123/locations/us-east1/indexEndpoints/3060310296007540736\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/965332343123/locations/us-east1/indexEndpoints/3060310296007540736')\n"
     ]
    }
   ],
   "source": [
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    description=DISPLAY_NAME,\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882784d-f7d3-425a-a48a-25e70cd43cbb",
   "metadata": {},
   "source": [
    "Deploy your index to the created endpoint. This can take up to 15 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e60833dd-4f73-4cab-abeb-99469286eeec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/965332343123/locations/us-east1/indexEndpoints/3060310296007540736\n"
     ]
    },
    {
     "ename": "AlreadyExists",
     "evalue": "409 There already exists a DeployedIndex with same ID \"deployed_index_id_unique\" deployed or being deployed at the following IndexEndpoint: projects/965332343123/locations/us-east1/indexEndpoints/3060310296007540736. Please use a different ID.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m (\n\u001b[1;32m   1176\u001b[0m     state,\n\u001b[1;32m   1177\u001b[0m     call,\n\u001b[1;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m )\n\u001b[0;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.ALREADY_EXISTS\n\tdetails = \"There already exists a DeployedIndex with same ID \"deployed_index_id_unique\" deployed or being deployed at the following IndexEndpoint: projects/965332343123/locations/us-east1/indexEndpoints/3060310296007540736. Please use a different ID.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:172.217.203.95:443 {grpc_message:\"There already exists a DeployedIndex with same ID \\\"deployed_index_id_unique\\\" deployed or being deployed at the following IndexEndpoint: projects/965332343123/locations/us-east1/indexEndpoints/3060310296007540736. Please use a different ID.\", grpc_status:6, created_time:\"2024-08-10T15:43:07.03497182+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAlreadyExists\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m DEPLOYED_INDEX_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeployed_index_id_unique\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m DEPLOYED_INDEX_ID\n\u001b[0;32m----> 6\u001b[0m my_index_endpoint \u001b[38;5;241m=\u001b[39m \u001b[43mmy_index_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtree_ah_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeployed_index_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEPLOYED_INDEX_ID\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m my_index_endpoint\u001b[38;5;241m.\u001b[39mdeployed_indexes\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/matching_engine/matching_engine_index_endpoint.py:1132\u001b[0m, in \u001b[0;36mMatchingEngineIndexEndpoint.deploy_index\u001b[0;34m(self, index, deployed_index_id, display_name, machine_type, min_replica_count, max_replica_count, enable_access_logging, reserved_ip_ranges, deployment_group, auth_config_audiences, auth_config_allowed_issuers, request_metadata, deploy_request_timeout)\u001b[0m\n\u001b[1;32m   1112\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_start_against_resource(\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeploying index\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1116\u001b[0m )\n\u001b[1;32m   1118\u001b[0m deployed_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_deployed_index(\n\u001b[1;32m   1119\u001b[0m     deployed_index_id\u001b[38;5;241m=\u001b[39mdeployed_index_id,\n\u001b[1;32m   1120\u001b[0m     index_resource_name\u001b[38;5;241m=\u001b[39mindex\u001b[38;5;241m.\u001b[39mresource_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     auth_config_allowed_issuers\u001b[38;5;241m=\u001b[39mauth_config_allowed_issuers,\n\u001b[1;32m   1130\u001b[0m )\n\u001b[0;32m-> 1132\u001b[0m deploy_lro \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployed_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployed_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_started_against_resource_with_lro(\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeploy index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, deploy_lro\n\u001b[1;32m   1141\u001b[0m )\n\u001b[1;32m   1143\u001b[0m deploy_lro\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/index_endpoint_service/client.py:1450\u001b[0m, in \u001b[0;36mIndexEndpointServiceClient.deploy_index\u001b[0;34m(self, request, index_endpoint, deployed_index, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1450\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;66;03m# Wrap the response in an operation future.\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m response \u001b[38;5;241m=\u001b[39m gac_operation\u001b[38;5;241m.\u001b[39mfrom_gapic(\n\u001b[1;32m   1459\u001b[0m     response,\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39moperations_client,\n\u001b[1;32m   1461\u001b[0m     index_endpoint_service\u001b[38;5;241m.\u001b[39mDeployIndexResponse,\n\u001b[1;32m   1462\u001b[0m     metadata_type\u001b[38;5;241m=\u001b[39mindex_endpoint_service\u001b[38;5;241m.\u001b[39mDeployIndexOperationMetadata,\n\u001b[1;32m   1463\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mAlreadyExists\u001b[0m: 409 There already exists a DeployedIndex with same ID \"deployed_index_id_unique\" deployed or being deployed at the following IndexEndpoint: projects/965332343123/locations/us-east1/indexEndpoints/3060310296007540736. Please use a different ID."
     ]
    }
   ],
   "source": [
    "DEPLOYED_INDEX_ID = \"deployed_index_id_unique\"\n",
    "\n",
    "DEPLOYED_INDEX_ID\n",
    "\n",
    "\n",
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac862a3-d3ce-4d80-9cab-a24744e1b98d",
   "metadata": {},
   "source": [
    "Verify number of declared items matches the number of embeddings. Each IndexEndpoint can have multiple indexes deployed to it. For each index, you can retrieve the number of deployed vectors using the index_endpoint._gca_resource.index_stats.vectors_count. The numbers may not match exactly due to potential rate-limiting failures incurred when using the embedding service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9321c952-a824-4190-ba25-fa1401b66abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 5000, Actual: 350\n"
     ]
    }
   ],
   "source": [
    "number_of_vectors = sum(\n",
    "    aiplatform.MatchingEngineIndex(\n",
    "        deployed_index.index\n",
    "    )._gca_resource.index_stats.vectors_count\n",
    "    for deployed_index in my_index_endpoint.deployed_indexes\n",
    ")\n",
    "\n",
    "print(f\"Expected: {BQ_NUM_ROWS}, Actual: {number_of_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c4849-cb53-423c-a5cc-55f3bcdd19d6",
   "metadata": {},
   "source": [
    "After you build your indexes, you may query against the deployed index to find nearest neighbors.\n",
    "\n",
    "Note: For the DOT_PRODUCT_DISTANCE distance type, the \"distance\" property returned with each MatchNeighbor actually refers to the similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069467d1-d3d0-4a42-a079-36de5af3c679",
   "metadata": {},
   "source": [
    "Create an embedding for a test question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f981cf49-bd14-460e-8a35-9f10fea16fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_embeddings = encode_texts_to_embeddings(sentences=[\"Install GPU for Tensorflow\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b4c1e-d97d-44e7-947c-0c93c458f6fe",
   "metadata": {},
   "source": [
    "Test the query to retrieve the similar embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2f879e7-93e1-4b7c-b603-b8e6057c2b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='50607994', distance=0.43464401364326477, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='31090638', distance=0.4175715446472168, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='43732991', distance=0.4172176718711853, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='73118840', distance=0.4167698621749878, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='13104630', distance=0.4123101234436035, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='53183869', distance=0.40891119837760925, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='5897308', distance=0.4022161364555359, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='50972198', distance=0.3863760828971863, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='50541851', distance=0.3844468593597412, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]),\n",
       "  MatchNeighbor(id='23581440', distance=0.38146770000457764, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=NUM_NEIGHBOURS,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d72ff-5dab-4fcf-885b-33ed1f91a062",
   "metadata": {},
   "source": [
    "Verify that the retrieved results are relevant by checking the StackOverflow links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e48ac9ba-d622-4ea6-b1c5-bd00078234fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stackoverflow.com/questions/50607994\n",
      "https://stackoverflow.com/questions/31090638\n",
      "https://stackoverflow.com/questions/43732991\n",
      "https://stackoverflow.com/questions/73118840\n",
      "https://stackoverflow.com/questions/13104630\n",
      "https://stackoverflow.com/questions/53183869\n",
      "https://stackoverflow.com/questions/5897308\n",
      "https://stackoverflow.com/questions/50972198\n",
      "https://stackoverflow.com/questions/50541851\n",
      "https://stackoverflow.com/questions/23581440\n"
     ]
    }
   ],
   "source": [
    "for match_index, neighbor in enumerate(response[0]):\n",
    "    print(f\"https://stackoverflow.com/questions/{neighbor.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc105456-4b3b-43ab-bcf2-cf529f11de21",
   "metadata": {},
   "source": [
    "Clean Up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c34730-1270-4fc4-b5a4-23b180d49680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "# Force undeployment of indexes and delete endpoint\n",
    "my_index_endpoint.delete(force=True)\n",
    "\n",
    "# Delete indexes\n",
    "tree_ah_index.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
